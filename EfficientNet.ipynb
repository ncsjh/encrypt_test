{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KIbmiWxHUxAR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, EfficientNetB7, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
    "#from efficientnet import EfficientNetB0, EfficientNetB3\n",
    "\n",
    "from PIL import Image\n",
    "import datetime\n",
    "#from efficientnet.preprocessing import center_crop_and_resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvhq-iuTIMuf"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "R3wCg6dI_8HG"
   },
   "outputs": [],
   "source": [
    "img_arg=Sequential(\n",
    "    [\n",
    "     preprocessing.RandomRotation(factor=0.15),\n",
    "     preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "     preprocessing.RandomFlip(),\n",
    "     preprocessing.RandomContrast(factor=0.1)\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUTdMc47UuFt"
   },
   "source": [
    "모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LVfLxBs924oa"
   },
   "outputs": [],
   "source": [
    "def build_model(n):\n",
    "#     inputs=layers.Input(shape=(600,600,3))  #B7을 이용할거니까 가로 세로 600\n",
    "    width=[224, 240, 260, 300, 380, 456, 528, 600] \n",
    "\n",
    "    inputs=layers.Input(shape=(width[n],width[n],3))  #B7을 이용할거니까 가로 세로 600\n",
    "    \n",
    "    x=img_arg(inputs)\n",
    "    \n",
    "    if n==0:\n",
    "        model=EfficientNetB0(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "    elif n==1:\n",
    "        model=EfficientNetB1(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "    elif n==2:\n",
    "        model=EfficientNetB2(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "    elif n==3:\n",
    "        model=EfficientNetB3(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "    elif n==4:\n",
    "        model=EfficientNetB4(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "    elif n==5:\n",
    "        model=EfficientNetB5(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "    elif n==6:\n",
    "        model=EfficientNetB6(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "\n",
    "    elif n==7:\n",
    "        model=EfficientNetB7(include_top=False,\n",
    "                           input_tensor=x,\n",
    "                           weights='imagenet'\n",
    "                           )\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.trainable=False\n",
    "\n",
    "  #build top\n",
    "    x=layers.GlobalAveragePooling2D(name='avg_pool')(model.output)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate=0.2\n",
    "    x=layers.Dropout(top_dropout_rate, name='top_dropout')(x)\n",
    "\n",
    "    outputs=layers.Dense(4,\n",
    "                       activation='softmax',\n",
    "                       name='pred')(x)\n",
    "  #compile \n",
    "    model=tf.keras.Model(inputs, outputs, name='EfficientNet')\n",
    "    optimizer=tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    model.save('test', save_format='h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzpOdi5gQLaT"
   },
   "source": [
    "EfficientNetB7(600*600 이미지) 모델을 불러오고 weights는 imagenet weights로 설정. class는 7개로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OnLMGZmFDMFs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2661,
     "status": "ok",
     "timestamp": 1656314626772,
     "user": {
      "displayName": "‍서정화[ 학부졸업 / 산업경영공학부 ]",
      "userId": "06282553350684864314"
     },
     "user_tz": -540
    },
    "id": "O-08SztJx5JN",
    "outputId": "9a496226-0285-451b-b8b3-7df321c697a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 224, 224, 3)  7           ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 1280)        0           ['top_activation[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1280)        5120        ['avg_pool[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " top_dropout (Dropout)          (None, 1280)         0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " pred (Dense)                   (None, 4)            5124        ['top_dropout[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,059,815\n",
      "Trainable params: 7,684\n",
      "Non-trainable params: 4,052,131\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CHXnFYTMydnh"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[50:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFv9dD79Cg1C"
   },
   "source": [
    "클래스 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZJ93UMR5DBye"
   },
   "outputs": [],
   "source": [
    "train_path='C:/Users/user/python/FacialClassification/train/resize_600'\n",
    "test_path='./FacialClassification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656314634384,
     "user": {
      "displayName": "‍서정화[ 학부졸업 / 산업경영공학부 ]",
      "userId": "06282553350684864314"
     },
     "user_tz": -540
    },
    "id": "ne_xpGnj9yWw",
    "outputId": "1296476e-9e2e-40fe-b35f-8c416976e85e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['기쁨', '당황', '분노', '슬픔']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(train_path)\n",
    "cls=[]\n",
    "for i in classes:\n",
    "    if len(i)<3:\n",
    "        cls.append(i)\n",
    "        \n",
    "cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEMMgYyiCkPC"
   },
   "source": [
    "데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CCHg3CwTALYa"
   },
   "outputs": [],
   "source": [
    "path='C:/Users/user/python/FacialClassification/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjeX14eHEOEW"
   },
   "source": [
    "이미지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLt5o58oE3o5"
   },
   "source": [
    "이미지의 주소는 train_path/test_path, classes[i], files[i][0] 의 형태로 불러올것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8evs8qG--Rtd"
   },
   "source": [
    "# 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1656314662078,
     "user": {
      "displayName": "‍서정화[ 학부졸업 / 산업경영공학부 ]",
      "userId": "06282553350684864314"
     },
     "user_tz": -540
    },
    "id": "ZXiEh1i8-TlZ",
    "outputId": "e6a2e1f5-25d9-4bf6-ff35-c9e53da5aad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 149743 files belonging to 4 classes.\n",
      "Found 1944 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds=tf.keras.preprocessing.image_dataset_from_directory(train_path,\n",
    "#                                                              image_size=(600,600),\n",
    "                                                             image_size=(240,240),\n",
    "                                                             seed=123)\n",
    "val_ds=tf.keras.preprocessing.image_dataset_from_directory(test_path,\n",
    "                                                             image_size=(240,240),\n",
    "#                                                            image_size=(600,600),\n",
    "                                                           seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1656314667150,
     "user": {
      "displayName": "‍서정화[ 학부졸업 / 산업경영공학부 ]",
      "userId": "06282553350684864314"
     },
     "user_tz": -540
    },
    "id": "ka1B1QXj_EVO",
    "outputId": "0b88bf5f-ecc7-49da-c8ab-a5d560fbc1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['기쁨', '당황', '분노', '슬픔']\n"
     ]
    }
   ],
   "source": [
    "class_names=train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yicEGSVNXgZT"
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "save_path = './Model_B0_192/model_{epoch:03d}_{val_accuracy:.4f}.h5'\n",
    "mckp=ModelCheckpoint(filepath=save_path,   # 저장할 위치\n",
    "                     monitor='val_accuracy',    # val_accuracy 기준으로다가\n",
    "                     save_best_only=True,     # 점수가 제일 높은 모델만 저장할거임\n",
    "                     verbose=1\n",
    "                     )\n",
    "early=EarlyStopping(monitor='val_accuracy',\n",
    "                    patience=30,             # val_accuracy가 5번까지는 안좋아져도 봐줌. \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name='learning_log'\n",
    "root_logdir=os.path.join(path, dir_name)\n",
    "if not os.path.exists(root_logdir):\n",
    "    os.mkdir(root_logdir)\n",
    "sub_dir_name=datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_log_dir=os.path.join(root_logdir, sub_dir_name)\n",
    "tensor_board=tf.keras.callbacks.TensorBoard(log_dir=tb_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./Model_B0_192'):\n",
    "    os.mkdir('./Model_B0_192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wOqQNRiu1at",
    "outputId": "b8796971-e1d4-4c38-fa2e-48393c3a382c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4680/4680 [==============================] - ETA: 0s - loss: 1.2641 - accuracy: 0.4561\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50051, saving model to ./Model_B0_192\\model_001_0.5005.h5\n",
      "4680/4680 [==============================] - 512s 106ms/step - loss: 1.2641 - accuracy: 0.4561 - val_loss: 1.3199 - val_accuracy: 0.5005\n",
      "Epoch 2/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.2136 - accuracy: 0.4734\n",
      "Epoch 00002: val_accuracy did not improve from 0.50051\n",
      "4680/4680 [==============================] - 494s 105ms/step - loss: 1.2135 - accuracy: 0.4734 - val_loss: 1.3057 - val_accuracy: 0.4748\n",
      "Epoch 3/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1939 - accuracy: 0.4800\n",
      "Epoch 00003: val_accuracy improved from 0.50051 to 0.51646, saving model to ./Model_B0_192\\model_003_0.5165.h5\n",
      "4680/4680 [==============================] - 491s 105ms/step - loss: 1.1939 - accuracy: 0.4799 - val_loss: 1.3236 - val_accuracy: 0.5165\n",
      "Epoch 4/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1817 - accuracy: 0.4872\n",
      "Epoch 00004: val_accuracy improved from 0.51646 to 0.54938, saving model to ./Model_B0_192\\model_004_0.5494.h5\n",
      "4680/4680 [==============================] - 491s 105ms/step - loss: 1.1817 - accuracy: 0.4872 - val_loss: 1.2894 - val_accuracy: 0.5494\n",
      "Epoch 5/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.4975\n",
      "Epoch 00005: val_accuracy improved from 0.54938 to 0.59928, saving model to ./Model_B0_192\\model_005_0.5993.h5\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1750 - accuracy: 0.4975 - val_loss: 1.3030 - val_accuracy: 0.5993\n",
      "Epoch 6/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1663 - accuracy: 0.5009\n",
      "Epoch 00006: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 551s 118ms/step - loss: 1.1663 - accuracy: 0.5009 - val_loss: 1.2758 - val_accuracy: 0.4861\n",
      "Epoch 7/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1673 - accuracy: 0.5067\n",
      "Epoch 00007: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 554s 118ms/step - loss: 1.1673 - accuracy: 0.5067 - val_loss: 1.2867 - val_accuracy: 0.5288\n",
      "Epoch 8/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1660 - accuracy: 0.5090\n",
      "Epoch 00008: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 559s 119ms/step - loss: 1.1660 - accuracy: 0.5090 - val_loss: 1.2630 - val_accuracy: 0.4671\n",
      "Epoch 9/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1626 - accuracy: 0.5103\n",
      "Epoch 00009: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 598s 128ms/step - loss: 1.1626 - accuracy: 0.5103 - val_loss: 1.2845 - val_accuracy: 0.5813\n",
      "Epoch 10/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1626 - accuracy: 0.5138\n",
      "Epoch 00010: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 609s 130ms/step - loss: 1.1626 - accuracy: 0.5138 - val_loss: 1.2604 - val_accuracy: 0.4892\n",
      "Epoch 11/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1598 - accuracy: 0.5145\n",
      "Epoch 00011: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 578s 123ms/step - loss: 1.1598 - accuracy: 0.5146 - val_loss: 1.2778 - val_accuracy: 0.5499\n",
      "Epoch 12/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1611 - accuracy: 0.5154\n",
      "Epoch 00012: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 558s 119ms/step - loss: 1.1611 - accuracy: 0.5154 - val_loss: 1.2856 - val_accuracy: 0.5705\n",
      "Epoch 13/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1628 - accuracy: 0.5174\n",
      "Epoch 00013: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 512s 109ms/step - loss: 1.1627 - accuracy: 0.5174 - val_loss: 1.2531 - val_accuracy: 0.4758\n",
      "Epoch 14/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1628 - accuracy: 0.5186\n",
      "Epoch 00014: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 514s 110ms/step - loss: 1.1628 - accuracy: 0.5186 - val_loss: 1.2684 - val_accuracy: 0.5895\n",
      "Epoch 15/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1598 - accuracy: 0.5172\n",
      "Epoch 00015: val_accuracy did not improve from 0.59928\n",
      "4680/4680 [==============================] - 509s 109ms/step - loss: 1.1598 - accuracy: 0.5172 - val_loss: 1.2732 - val_accuracy: 0.5525\n"
     ]
    }
   ],
   "source": [
    "h=model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=500,\n",
    "            callbacks=[mckp, early, tensor_board],\n",
    "            batch_size=32\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SsjtsJSOdYok"
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "save_path = './Model_B0_112/model_{epoch:03d}_{val_accuracy:.4f}.h5'\n",
    "mckp=ModelCheckpoint(filepath=save_path,   # 저장할 위치\n",
    "                     monitor='val_accuracy',    # val_accuracy 기준으로다가\n",
    "                     save_best_only=True,     # 점수가 제일 높은 모델만 저장할거임\n",
    "                     verbose=1\n",
    "                     )\n",
    "early=EarlyStopping(monitor='val_accuracy',\n",
    "                    patience=30,             # val_accuracy가 5번까지는 안좋아져도 봐줌. \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1617 - accuracy: 0.5181\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56636, saving model to ./Model_B0_112\\model_001_0.5664.h5\n",
      "4680/4680 [==============================] - 528s 112ms/step - loss: 1.1617 - accuracy: 0.5181 - val_loss: 1.2771 - val_accuracy: 0.5664\n",
      "Epoch 2/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1622 - accuracy: 0.5170\n",
      "Epoch 00002: val_accuracy did not improve from 0.56636\n",
      "4680/4680 [==============================] - 510s 109ms/step - loss: 1.1622 - accuracy: 0.5170 - val_loss: 1.2619 - val_accuracy: 0.5098\n",
      "Epoch 3/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1610 - accuracy: 0.5187\n",
      "Epoch 00003: val_accuracy improved from 0.56636 to 0.59516, saving model to ./Model_B0_112\\model_003_0.5952.h5\n",
      "4680/4680 [==============================] - 534s 114ms/step - loss: 1.1610 - accuracy: 0.5187 - val_loss: 1.2760 - val_accuracy: 0.5952\n",
      "Epoch 4/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1607 - accuracy: 0.5164\n",
      "Epoch 00004: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 565s 121ms/step - loss: 1.1607 - accuracy: 0.5164 - val_loss: 1.2739 - val_accuracy: 0.5412\n",
      "Epoch 5/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1613 - accuracy: 0.5180\n",
      "Epoch 00005: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 571s 122ms/step - loss: 1.1613 - accuracy: 0.5180 - val_loss: 1.2768 - val_accuracy: 0.5833\n",
      "Epoch 6/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1617 - accuracy: 0.5172\n",
      "Epoch 00006: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 562s 120ms/step - loss: 1.1617 - accuracy: 0.5172 - val_loss: 1.2654 - val_accuracy: 0.5581\n",
      "Epoch 7/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1592 - accuracy: 0.5156\n",
      "Epoch 00007: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 544s 116ms/step - loss: 1.1592 - accuracy: 0.5156 - val_loss: 1.2891 - val_accuracy: 0.5684\n",
      "Epoch 8/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1608 - accuracy: 0.5175\n",
      "Epoch 00008: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 504s 108ms/step - loss: 1.1608 - accuracy: 0.5175 - val_loss: 1.2684 - val_accuracy: 0.4789\n",
      "Epoch 9/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1604 - accuracy: 0.5185\n",
      "Epoch 00009: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1604 - accuracy: 0.5185 - val_loss: 1.2736 - val_accuracy: 0.5576\n",
      "Epoch 10/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1595 - accuracy: 0.5175\n",
      "Epoch 00010: val_accuracy did not improve from 0.59516\n",
      "4680/4680 [==============================] - 497s 106ms/step - loss: 1.1595 - accuracy: 0.5175 - val_loss: 1.2752 - val_accuracy: 0.5761\n",
      "Epoch 11/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1608 - accuracy: 0.5187\n",
      "Epoch 00011: val_accuracy improved from 0.59516 to 0.63735, saving model to ./Model_B0_112\\model_011_0.6373.h5\n",
      "4680/4680 [==============================] - 495s 106ms/step - loss: 1.1608 - accuracy: 0.5187 - val_loss: 1.2864 - val_accuracy: 0.6373\n",
      "Epoch 12/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1578 - accuracy: 0.5164\n",
      "Epoch 00012: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 496s 106ms/step - loss: 1.1578 - accuracy: 0.5164 - val_loss: 1.2657 - val_accuracy: 0.4805\n",
      "Epoch 13/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1601 - accuracy: 0.5170\n",
      "Epoch 00013: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 495s 106ms/step - loss: 1.1601 - accuracy: 0.5170 - val_loss: 1.2607 - val_accuracy: 0.5432\n",
      "Epoch 14/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1581 - accuracy: 0.5177\n",
      "Epoch 00014: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 495s 106ms/step - loss: 1.1581 - accuracy: 0.5177 - val_loss: 1.2829 - val_accuracy: 0.5535\n",
      "Epoch 15/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1610 - accuracy: 0.5196\n",
      "Epoch 00015: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 498s 106ms/step - loss: 1.1610 - accuracy: 0.5197 - val_loss: 1.2693 - val_accuracy: 0.5802\n",
      "Epoch 16/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1611 - accuracy: 0.5177\n",
      "Epoch 00016: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 497s 106ms/step - loss: 1.1611 - accuracy: 0.5177 - val_loss: 1.2655 - val_accuracy: 0.4439\n",
      "Epoch 17/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1607 - accuracy: 0.5189\n",
      "Epoch 00017: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 498s 106ms/step - loss: 1.1607 - accuracy: 0.5189 - val_loss: 1.2801 - val_accuracy: 0.5597\n",
      "Epoch 18/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1604 - accuracy: 0.5171\n",
      "Epoch 00018: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 498s 106ms/step - loss: 1.1604 - accuracy: 0.5171 - val_loss: 1.2772 - val_accuracy: 0.5463\n",
      "Epoch 19/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1587 - accuracy: 0.5177\n",
      "Epoch 00019: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 498s 106ms/step - loss: 1.1587 - accuracy: 0.5177 - val_loss: 1.2717 - val_accuracy: 0.5628\n",
      "Epoch 20/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1594 - accuracy: 0.5164\n",
      "Epoch 00020: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1594 - accuracy: 0.5164 - val_loss: 1.2612 - val_accuracy: 0.5195\n",
      "Epoch 21/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1595 - accuracy: 0.5189\n",
      "Epoch 00021: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1595 - accuracy: 0.5189 - val_loss: 1.2719 - val_accuracy: 0.5427\n",
      "Epoch 22/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1582 - accuracy: 0.5182\n",
      "Epoch 00022: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 498s 106ms/step - loss: 1.1582 - accuracy: 0.5182 - val_loss: 1.2594 - val_accuracy: 0.5159\n",
      "Epoch 23/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1593 - accuracy: 0.5179\n",
      "Epoch 00023: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1593 - accuracy: 0.5179 - val_loss: 1.2589 - val_accuracy: 0.5098\n",
      "Epoch 24/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1590 - accuracy: 0.5171\n",
      "Epoch 00024: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 498s 106ms/step - loss: 1.1590 - accuracy: 0.5171 - val_loss: 1.2648 - val_accuracy: 0.5658\n",
      "Epoch 25/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1598 - accuracy: 0.5186\n",
      "Epoch 00025: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1599 - accuracy: 0.5186 - val_loss: 1.2577 - val_accuracy: 0.5072\n",
      "Epoch 26/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1583 - accuracy: 0.5170\n",
      "Epoch 00026: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1584 - accuracy: 0.5170 - val_loss: 1.2721 - val_accuracy: 0.5401\n",
      "Epoch 27/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1620 - accuracy: 0.5183\n",
      "Epoch 00027: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1620 - accuracy: 0.5183 - val_loss: 1.2490 - val_accuracy: 0.5309\n",
      "Epoch 28/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1593 - accuracy: 0.5188\n",
      "Epoch 00028: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 499s 107ms/step - loss: 1.1593 - accuracy: 0.5188 - val_loss: 1.2697 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1598 - accuracy: 0.5186\n",
      "Epoch 00029: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 501s 107ms/step - loss: 1.1598 - accuracy: 0.5186 - val_loss: 1.2594 - val_accuracy: 0.5617\n",
      "Epoch 30/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1592 - accuracy: 0.5187\n",
      "Epoch 00030: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 501s 107ms/step - loss: 1.1592 - accuracy: 0.5187 - val_loss: 1.2482 - val_accuracy: 0.4408\n",
      "Epoch 31/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1620 - accuracy: 0.5181\n",
      "Epoch 00031: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1620 - accuracy: 0.5181 - val_loss: 1.2741 - val_accuracy: 0.5983\n",
      "Epoch 32/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1599 - accuracy: 0.5176\n",
      "Epoch 00032: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1599 - accuracy: 0.5176 - val_loss: 1.2853 - val_accuracy: 0.5833\n",
      "Epoch 33/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1599 - accuracy: 0.5186\n",
      "Epoch 00033: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 501s 107ms/step - loss: 1.1599 - accuracy: 0.5187 - val_loss: 1.2589 - val_accuracy: 0.4722\n",
      "Epoch 34/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1586 - accuracy: 0.5181\n",
      "Epoch 00034: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1586 - accuracy: 0.5180 - val_loss: 1.2591 - val_accuracy: 0.4769\n",
      "Epoch 35/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1597 - accuracy: 0.5178\n",
      "Epoch 00035: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 501s 107ms/step - loss: 1.1597 - accuracy: 0.5178 - val_loss: 1.2564 - val_accuracy: 0.4902\n",
      "Epoch 36/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1592 - accuracy: 0.5180\n",
      "Epoch 00036: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1592 - accuracy: 0.5180 - val_loss: 1.2527 - val_accuracy: 0.4558\n",
      "Epoch 37/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1597 - accuracy: 0.5190\n",
      "Epoch 00037: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 501s 107ms/step - loss: 1.1597 - accuracy: 0.5190 - val_loss: 1.2599 - val_accuracy: 0.5350\n",
      "Epoch 38/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1588 - accuracy: 0.5177\n",
      "Epoch 00038: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1588 - accuracy: 0.5177 - val_loss: 1.2800 - val_accuracy: 0.5761\n",
      "Epoch 39/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1604 - accuracy: 0.5191\n",
      "Epoch 00039: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 501s 107ms/step - loss: 1.1604 - accuracy: 0.5191 - val_loss: 1.2703 - val_accuracy: 0.5391\n",
      "Epoch 40/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1603 - accuracy: 0.5183\n",
      "Epoch 00040: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1603 - accuracy: 0.5183 - val_loss: 1.2726 - val_accuracy: 0.4861\n",
      "Epoch 41/500\n",
      "4679/4680 [============================>.] - ETA: 0s - loss: 1.1611 - accuracy: 0.5183\n",
      "Epoch 00041: val_accuracy did not improve from 0.63735\n",
      "4680/4680 [==============================] - 500s 107ms/step - loss: 1.1611 - accuracy: 0.5183 - val_loss: 1.2687 - val_accuracy: 0.5134\n"
     ]
    }
   ],
   "source": [
    "h=model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=500,\n",
    "            callbacks=[mckp, early, tensor_board],\n",
    "            batch_size=32\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1모델, Trainable layer 절반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Model_B1_harf/model_{epoch:03d}_{val_accuracy:.4f}.h5'\n",
    "mckp=ModelCheckpoint(filepath=save_path,   # 저장할 위치\n",
    "                     monitor='val_accuracy',    # val_accuracy 기준으로다가\n",
    "                     save_best_only=True,     # 점수가 제일 높은 모델만 저장할거임\n",
    "                     verbose=1\n",
    "                     )\n",
    "early=EarlyStopping(monitor='val_accuracy',\n",
    "                    patience=30,             # val_accuracy가 5번까지는 안좋아져도 봐줌. \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SmDAqZIHgAu7"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[170:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "codvP1nAtYMO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4680/4680 [==============================] - ETA: 0s - loss: 1.2733 - accuracy: 0.4622\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.42798, saving model to ./Model_B1_harf\\model_001_0.4280.h5\n",
      "4680/4680 [==============================] - 739s 154ms/step - loss: 1.2733 - accuracy: 0.4622 - val_loss: 1.3511 - val_accuracy: 0.4280\n",
      "Epoch 2/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.2224 - accuracy: 0.4825\n",
      "Epoch 00002: val_accuracy improved from 0.42798 to 0.57716, saving model to ./Model_B1_harf\\model_002_0.5772.h5\n",
      "4680/4680 [==============================] - 703s 150ms/step - loss: 1.2224 - accuracy: 0.4825 - val_loss: 1.3553 - val_accuracy: 0.5772\n",
      "Epoch 3/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.2045 - accuracy: 0.4963\n",
      "Epoch 00003: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 697s 149ms/step - loss: 1.2045 - accuracy: 0.4963 - val_loss: 1.2808 - val_accuracy: 0.5401\n",
      "Epoch 4/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1923 - accuracy: 0.5061\n",
      "Epoch 00004: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 692s 148ms/step - loss: 1.1923 - accuracy: 0.5061 - val_loss: 1.2648 - val_accuracy: 0.4717\n",
      "Epoch 5/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1826 - accuracy: 0.5170\n",
      "Epoch 00005: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 690s 147ms/step - loss: 1.1826 - accuracy: 0.5170 - val_loss: 1.2643 - val_accuracy: 0.4954\n",
      "Epoch 6/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1754 - accuracy: 0.5214\n",
      "Epoch 00006: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 689s 147ms/step - loss: 1.1754 - accuracy: 0.5214 - val_loss: 1.2668 - val_accuracy: 0.5082\n",
      "Epoch 7/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1741 - accuracy: 0.5289\n",
      "Epoch 00007: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 681s 145ms/step - loss: 1.1741 - accuracy: 0.5289 - val_loss: 1.2757 - val_accuracy: 0.5540\n",
      "Epoch 8/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1720 - accuracy: 0.5331\n",
      "Epoch 00008: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1720 - accuracy: 0.5331 - val_loss: 1.2518 - val_accuracy: 0.4753\n",
      "Epoch 9/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1717 - accuracy: 0.5341\n",
      "Epoch 00009: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 681s 145ms/step - loss: 1.1717 - accuracy: 0.5341 - val_loss: 1.2851 - val_accuracy: 0.5046\n",
      "Epoch 10/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1743 - accuracy: 0.5393\n",
      "Epoch 00010: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 673s 144ms/step - loss: 1.1743 - accuracy: 0.5393 - val_loss: 1.2684 - val_accuracy: 0.5412\n",
      "Epoch 11/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1699 - accuracy: 0.5370\n",
      "Epoch 00011: val_accuracy did not improve from 0.57716\n",
      "4680/4680 [==============================] - 678s 145ms/step - loss: 1.1699 - accuracy: 0.5370 - val_loss: 1.2775 - val_accuracy: 0.5350\n",
      "Epoch 12/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1717 - accuracy: 0.5393\n",
      "Epoch 00012: val_accuracy improved from 0.57716 to 0.60802, saving model to ./Model_B1_harf\\model_012_0.6080.h5\n",
      "4680/4680 [==============================] - 677s 145ms/step - loss: 1.1717 - accuracy: 0.5393 - val_loss: 1.2975 - val_accuracy: 0.6080\n",
      "Epoch 13/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1713 - accuracy: 0.5394\n",
      "Epoch 00013: val_accuracy did not improve from 0.60802\n",
      "4680/4680 [==============================] - 673s 144ms/step - loss: 1.1713 - accuracy: 0.5394 - val_loss: 1.2775 - val_accuracy: 0.4871\n",
      "Epoch 14/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1711 - accuracy: 0.5428\n",
      "Epoch 00014: val_accuracy did not improve from 0.60802\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1711 - accuracy: 0.5428 - val_loss: 1.2704 - val_accuracy: 0.5802\n",
      "Epoch 15/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.5414\n",
      "Epoch 00015: val_accuracy did not improve from 0.60802\n",
      "4680/4680 [==============================] - 669s 143ms/step - loss: 1.1696 - accuracy: 0.5414 - val_loss: 1.2490 - val_accuracy: 0.5324\n",
      "Epoch 16/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1719 - accuracy: 0.5407\n",
      "Epoch 00016: val_accuracy did not improve from 0.60802\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1719 - accuracy: 0.5407 - val_loss: 1.2675 - val_accuracy: 0.5118\n",
      "Epoch 17/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.5434\n",
      "Epoch 00017: val_accuracy did not improve from 0.60802\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1696 - accuracy: 0.5434 - val_loss: 1.2592 - val_accuracy: 0.5869\n",
      "Epoch 18/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.5415\n",
      "Epoch 00018: val_accuracy did not improve from 0.60802\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1712 - accuracy: 0.5415 - val_loss: 1.2790 - val_accuracy: 0.5561\n",
      "Epoch 19/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1715 - accuracy: 0.5430\n",
      "Epoch 00019: val_accuracy improved from 0.60802 to 0.62706, saving model to ./Model_B1_harf\\model_019_0.6271.h5\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1715 - accuracy: 0.5430 - val_loss: 1.2972 - val_accuracy: 0.6271\n",
      "Epoch 20/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1681 - accuracy: 0.5411\n",
      "Epoch 00020: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1681 - accuracy: 0.5411 - val_loss: 1.2657 - val_accuracy: 0.5643\n",
      "Epoch 21/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.5396\n",
      "Epoch 00021: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1684 - accuracy: 0.5396 - val_loss: 1.2787 - val_accuracy: 0.6075\n",
      "Epoch 22/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1707 - accuracy: 0.5436\n",
      "Epoch 00022: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1707 - accuracy: 0.5436 - val_loss: 1.2611 - val_accuracy: 0.5412\n",
      "Epoch 23/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1695 - accuracy: 0.5427\n",
      "Epoch 00023: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 672s 143ms/step - loss: 1.1695 - accuracy: 0.5427 - val_loss: 1.2424 - val_accuracy: 0.5664\n",
      "Epoch 24/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1697 - accuracy: 0.5421\n",
      "Epoch 00024: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 672s 144ms/step - loss: 1.1697 - accuracy: 0.5421 - val_loss: 1.2710 - val_accuracy: 0.5602\n",
      "Epoch 25/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1700 - accuracy: 0.5439\n",
      "Epoch 00025: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1700 - accuracy: 0.5439 - val_loss: 1.2827 - val_accuracy: 0.5597\n",
      "Epoch 26/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1698 - accuracy: 0.5417\n",
      "Epoch 00026: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1698 - accuracy: 0.5417 - val_loss: 1.2643 - val_accuracy: 0.5854\n",
      "Epoch 27/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.5425\n",
      "Epoch 00027: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1712 - accuracy: 0.5425 - val_loss: 1.2600 - val_accuracy: 0.6127\n",
      "Epoch 28/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1713 - accuracy: 0.5438\n",
      "Epoch 00028: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1713 - accuracy: 0.5438 - val_loss: 1.2742 - val_accuracy: 0.5458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1703 - accuracy: 0.5428\n",
      "Epoch 00029: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 669s 143ms/step - loss: 1.1703 - accuracy: 0.5428 - val_loss: 1.2666 - val_accuracy: 0.5694\n",
      "Epoch 30/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1704 - accuracy: 0.5445\n",
      "Epoch 00030: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 669s 143ms/step - loss: 1.1704 - accuracy: 0.5445 - val_loss: 1.2742 - val_accuracy: 0.5427\n",
      "Epoch 31/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1695 - accuracy: 0.5408\n",
      "Epoch 00031: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 669s 143ms/step - loss: 1.1695 - accuracy: 0.5408 - val_loss: 1.2563 - val_accuracy: 0.5705\n",
      "Epoch 32/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.5421\n",
      "Epoch 00032: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1696 - accuracy: 0.5421 - val_loss: 1.2669 - val_accuracy: 0.5360\n",
      "Epoch 33/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1703 - accuracy: 0.5440\n",
      "Epoch 00033: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 669s 143ms/step - loss: 1.1703 - accuracy: 0.5440 - val_loss: 1.2844 - val_accuracy: 0.5123\n",
      "Epoch 34/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.5439\n",
      "Epoch 00034: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1684 - accuracy: 0.5439 - val_loss: 1.2758 - val_accuracy: 0.5633\n",
      "Epoch 35/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.5428\n",
      "Epoch 00035: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1684 - accuracy: 0.5428 - val_loss: 1.2519 - val_accuracy: 0.5448\n",
      "Epoch 36/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1677 - accuracy: 0.5436\n",
      "Epoch 00036: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 675s 144ms/step - loss: 1.1677 - accuracy: 0.5436 - val_loss: 1.2749 - val_accuracy: 0.5736\n",
      "Epoch 37/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1691 - accuracy: 0.5416\n",
      "Epoch 00037: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1691 - accuracy: 0.5416 - val_loss: 1.2790 - val_accuracy: 0.5293\n",
      "Epoch 38/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.5421\n",
      "Epoch 00038: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1696 - accuracy: 0.5421 - val_loss: 1.2775 - val_accuracy: 0.5303\n",
      "Epoch 39/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1699 - accuracy: 0.5431\n",
      "Epoch 00039: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1699 - accuracy: 0.5431 - val_loss: 1.2465 - val_accuracy: 0.5360\n",
      "Epoch 40/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1682 - accuracy: 0.5407\n",
      "Epoch 00040: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1682 - accuracy: 0.5407 - val_loss: 1.2794 - val_accuracy: 0.5370\n",
      "Epoch 41/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1686 - accuracy: 0.5409\n",
      "Epoch 00041: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1686 - accuracy: 0.5409 - val_loss: 1.2661 - val_accuracy: 0.6183\n",
      "Epoch 42/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1686 - accuracy: 0.5431\n",
      "Epoch 00042: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1686 - accuracy: 0.5431 - val_loss: 1.2735 - val_accuracy: 0.4110\n",
      "Epoch 43/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1695 - accuracy: 0.5425\n",
      "Epoch 00043: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1695 - accuracy: 0.5425 - val_loss: 1.2813 - val_accuracy: 0.5478\n",
      "Epoch 44/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1674 - accuracy: 0.5423\n",
      "Epoch 00044: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1674 - accuracy: 0.5423 - val_loss: 1.2419 - val_accuracy: 0.5283\n",
      "Epoch 45/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1705 - accuracy: 0.5417\n",
      "Epoch 00045: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1705 - accuracy: 0.5417 - val_loss: 1.2657 - val_accuracy: 0.6096\n",
      "Epoch 46/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.5424\n",
      "Epoch 00046: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1684 - accuracy: 0.5424 - val_loss: 1.2670 - val_accuracy: 0.4861\n",
      "Epoch 47/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1707 - accuracy: 0.5431\n",
      "Epoch 00047: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1707 - accuracy: 0.5431 - val_loss: 1.2687 - val_accuracy: 0.4933\n",
      "Epoch 48/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1682 - accuracy: 0.5415\n",
      "Epoch 00048: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 671s 143ms/step - loss: 1.1682 - accuracy: 0.5415 - val_loss: 1.2634 - val_accuracy: 0.5751\n",
      "Epoch 49/500\n",
      "4680/4680 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.5437\n",
      "Epoch 00049: val_accuracy did not improve from 0.62706\n",
      "4680/4680 [==============================] - 670s 143ms/step - loss: 1.1696 - accuracy: 0.5437 - val_loss: 1.2715 - val_accuracy: 0.5694\n"
     ]
    }
   ],
   "source": [
    "h1_1=model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=500,\n",
    "            callbacks=[mckp, early],\n",
    "            batch_size=32\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1모델, Trainable Layer 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-pih2Kjrh5YN"
   },
   "outputs": [],
   "source": [
    "save_path = './Model_B1_quarter/model_{epoch:03d}_{val_accuracy:.4f}.h5'\n",
    "mckp=ModelCheckpoint(filepath=save_path,   # 저장할 위치\n",
    "                     monitor='val_accuracy',    # val_accuracy 기준으로다가\n",
    "                     save_best_only=True,     # 점수가 제일 높은 모델만 저장할거임\n",
    "                     verbose=1\n",
    "                     )\n",
    "early=EarlyStopping(monitor='val_accuracy',\n",
    "                    patience=30,             # val_accuracy가 5번까지는 안좋아져도 봐줌. \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19268\\2530772509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[len(model.layers)/4:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmDAqZIHgAu7"
   },
   "outputs": [],
   "source": [
    "h1_2=model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=500,\n",
    "            callbacks=[mckp, early],\n",
    "            batch_size=32\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1모델, Trainable Layer 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Model_B1_3quarter/model_{epoch:03d}_{val_accuracy:.4f}.h5'\n",
    "mckp=ModelCheckpoint(filepath=save_path,   # 저장할 위치\n",
    "                     monitor='val_accuracy',    # val_accuracy 기준으로다가\n",
    "                     save_best_only=True,     # 점수가 제일 높은 모델만 저장할거임\n",
    "                     verbose=1\n",
    "                     )\n",
    "early=EarlyStopping(monitor='val_accuracy',\n",
    "                    patience=30,             # val_accuracy가 5번까지는 안좋아져도 봐줌. \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[3*len(model.layers)/4:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_3=model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=500,\n",
    "            callbacks=[mckp, early],\n",
    "            batch_size=32\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EfficientNet.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
